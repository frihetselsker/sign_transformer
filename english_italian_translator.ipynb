{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:40:16.527997Z",
     "start_time": "2025-03-31T21:40:16.522998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ],
   "id": "c9848c51519985b8",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:40:18.166869Z",
     "start_time": "2025-03-31T21:40:18.161869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Device-independent code\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ],
   "id": "ce20dc0b63a10af0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:43:31.520452Z",
     "start_time": "2025-03-31T21:43:31.515042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to read the file and extract pairs\n",
    "def read_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.read().strip().split('\\n')\n",
    "    pairs = [[s for s in line.split(' -> ')] for line in lines]\n",
    "    return pairs\n",
    "\n",
    "def tokenize(sentence):\n",
    "  return sentence.lower().split()\n",
    "\n",
    "# Tokenize and build vocabularies\n",
    "def build_vocab(pairs):\n",
    "    eng_vocab = set()\n",
    "    ita_vocab = set()\n",
    "    for eng, ita in pairs:\n",
    "        eng_vocab.update(tokenize(eng))\n",
    "        ita_vocab.update(tokenize(ita))\n",
    "    return eng_vocab, ita_vocab"
   ],
   "id": "f6779afce6e2904",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:43:43.892623Z",
     "start_time": "2025-03-31T21:43:43.532176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Path to your text file\n",
    "file_path = 'eng_ita_v2.txt'\n",
    "\n",
    "# Process the data\n",
    "pairs = read_data(file_path)\n",
    "english_vocab, italian_vocab = build_vocab(pairs)\n",
    "\n",
    "# Creating word to integer mapping\n",
    "eng_word2int = {word: i for i, word in enumerate(english_vocab)}\n",
    "ita_word2int = {word: i for i, word in enumerate(italian_vocab)}\n",
    "\n",
    "# Creating integer to word mapping\n",
    "eng_int2word = {i: word for word, i in eng_word2int.items()}\n",
    "ita_int2word = {i: word for word, i in ita_word2int.items()}\n",
    "\n",
    "print('English vocabulary size:', len(english_vocab))\n",
    "print('Italian vocabulary size:', len(italian_vocab))"
   ],
   "id": "8f004b63bd530a51",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocabulary size: 4997\n",
      "Italian vocabulary size: 13673\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:44:38.812772Z",
     "start_time": "2025-03-31T21:44:38.806908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "eng_example = \"Who are you\"\n",
    "ita_example = \"chi sei tu\"\n",
    "\n",
    "# Encoding\n",
    "eng_encoded = np.array([eng_word2int[word] for word in tokenize(eng_example)], dtype=np.int32)\n",
    "ita_encoded = np.array([ita_word2int[word] for word in tokenize(ita_example)], dtype=np.int32)\n",
    "\n",
    "print('English text encoded:', eng_encoded)\n",
    "print('Italian text encoded:', ita_encoded)\n",
    "\n",
    "# Decoding\n",
    "print('Decoded English:', ' '.join([eng_int2word[i] for i in eng_encoded]))\n",
    "print('Decoded Italian:', ' '.join([ita_int2word[i] for i in ita_encoded]))"
   ],
   "id": "26fcd7677db45540",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English text encoded: [3080  111 3851]\n",
      "Italian text encoded: [2025 4671   58]\n",
      "Decoded English: who are you\n",
      "Decoded Italian: chi sei tu\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:45:05.412062Z",
     "start_time": "2025-03-31T21:45:05.400063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Special tokens\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "EOS_TOKEN = \"<EOS>\"\n",
    "SOS_TOKEN = \"<SOS>\"\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "# Update the function to create mappings to include the SOS token\n",
    "def create_mappings(vocab):\n",
    "    vocab = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN] + sorted(vocab)\n",
    "    word2int = {word: i for i, word in enumerate(vocab)}\n",
    "    int2word = {i: word for word, i in word2int.items()}\n",
    "    return word2int, int2word\n",
    "\n",
    "# Update the vocabularies\n",
    "eng_word2int, eng_int2word = create_mappings(english_vocab)\n",
    "ita_word2int, ita_int2word = create_mappings(italian_vocab)"
   ],
   "id": "4c14f5350a7d3af9",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:46:51.535915Z",
     "start_time": "2025-03-31T21:46:51.528915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, pairs, eng_word2int, ita_word2int):\n",
    "        self.pairs = pairs\n",
    "        self.eng_word2int = eng_word2int\n",
    "        self.ita_word2int = ita_word2int\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng, ita = self.pairs[idx]\n",
    "        eng_tensor = torch.tensor([self.eng_word2int[word] for word in tokenize(eng)] + [self.eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        ita_tensor = torch.tensor([self.ita_word2int[word] for word in tokenize(ita)] + [self.ita_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        return eng_tensor, ita_tensor\n",
    "\n",
    "# Custom collate function to handle padding\n",
    "def collate_fn(batch):\n",
    "    eng_batch, ita_batch = zip(*batch)\n",
    "    eng_batch_padded = pad_sequence(eng_batch, batch_first=True, padding_value=eng_word2int[PAD_TOKEN])\n",
    "    ita_batch_padded = pad_sequence(ita_batch, batch_first=True, padding_value=ita_word2int[PAD_TOKEN])\n",
    "    return eng_batch_padded, ita_batch_padded"
   ],
   "id": "36644fb8db7bc316",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:47:21.333007Z",
     "start_time": "2025-03-31T21:47:21.328325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Create the dataset and DataLoader\n",
    "translation_dataset = TranslationDataset(pairs, eng_word2int, ita_word2int)\n",
    "batch_size = 64\n",
    "translation_dataloader = DataLoader(translation_dataset, batch_size=batch_size, shuffle=True,  drop_last=True, collate_fn=collate_fn)\n",
    "\n",
    "print(\"Translation samples: \", len(translation_dataset))\n",
    "print(\"Translation batches: \", len(translation_dataloader))"
   ],
   "id": "79f0cbbd4c0fc963",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation samples:  120746\n",
      "Translation batches:  1886\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:47:46.151797Z",
     "start_time": "2025-03-31T21:47:46.132937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example: iterating over the DataLoader\n",
    "for eng, ita in translation_dataloader:\n",
    "    print(\"English batch:\", eng)\n",
    "    print(\"Italian batch:\", ita)\n",
    "    break # remove this to iterate over the whole dataset"
   ],
   "id": "5c34dfc4e932b34c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English batch: tensor([[4478, 4787,  827, 3924,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [2149, 1849, 4478, 2507, 2629,    2,    0,    0,    0,    0,    0],\n",
      "        [2146, 4787,   43, 4467, 1853, 2998, 4855, 4392, 3134, 3436,    2],\n",
      "        [2146, 4883, 1671, 2799, 2081,  632, 2866,    2,    0,    0,    0],\n",
      "        [4426, 1016, 4690, 4467,  448, 4467, 1760,    2,    0,    0,    0],\n",
      "        [4478, 4917, 2508,  402, 1444,    2,    0,    0,    0,    0,    0],\n",
      "        [4407, 4842,  170, 4472,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [2303, 2308,  156, 3614, 4467, 1853,    2,    0,    0,    0,    0],\n",
      "        [2146, 1325, 4416, 4478, 2378, 2055,    2,    0,    0,    0,    0],\n",
      "        [2146,  305,   37, 3950, 2931, 3156,    2,    0,    0,    0,    0],\n",
      "        [4478, 2772, 3413,    2,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [2146, 4416, 4478,  654, 4885,    2,    0,    0,    0,    0,    0],\n",
      "        [2583, 4787, 1895,    2,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [4478, 4883,  402, 2031,  425, 2629,    2,    0,    0,    0,    0],\n",
      "        [4848,  654, 2146, 1305,   43, 2308,    2,    0,    0,    0,    0],\n",
      "        [2484, 3946, 1317, 2494,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [4478, 1222, 4155, 4306,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [4478,  188, 2629,  253,  991,    2,    0,    0,    0,    0,    0],\n",
      "        [2308, 4793, 1796, 1318, 4389,    2,    0,    0,    0,    0,    0],\n",
      "        [2146,  171, 2360,   37, 2124, 4325,    2,    0,    0,    0,    0],\n",
      "        [4808, 1325, 2833,  294,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [2146, 2506,  510,    2,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [4848, 1221, 4985, 3478,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [ 171, 2146, 4306, 4488, 2781,    2,    0,    0,    0,    0,    0],\n",
      "        [1325, 1958, 2998, 4905, 4478,    2,    0,    0,    0,    0,    0],\n",
      "        [4392, 4741,  287, 4392,  814,   37, 3407,    2,    0,    0,    0],\n",
      "        [2146,  171, 2883, 4392,  672, 2931, 4392, 2853, 4330,    2,    0],\n",
      "        [4478, 2306,   37, 1867,  851,    2,    0,    0,    0,    0,    0],\n",
      "        [2874, 2931, 4687, 4842, 3700, 4905, 4392, 4291,    2,    0,    0],\n",
      "        [2146, 4416, 4478, 2303, 1720,    2,    0,    0,    0,    0,    0],\n",
      "        [2146, 4428, 2146, 3708, 4016, 2146, 2395,    2,    0,    0,    0],\n",
      "        [4423, 2604, 2652, 1078,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [4478, 3862, 1846, 2629,   37,  480, 3289,    2,    0,    0,    0],\n",
      "        [2303, 3825, 2325,    2,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [2146, 4776, 4985, 4467, 1987, 1796,    2,    0,    0,    0,    0],\n",
      "        [4392,  520, 2303, 4488, 1556,    2,    0,    0,    0,    0,    0],\n",
      "        [4478, 2303, 2138,    2,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [3825, 4778, 4467, 2377, 2652,    2,    0,    0,    0,    0,    0],\n",
      "        [2146, 1325, 4416, 4478, 2303, 3721,    2,    0,    0,    0,    0],\n",
      "        [4988, 3009,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [4011,  284, 2679, 4819, 2605,    2,    0,    0,    0,    0,    0],\n",
      "        [ 536, 4161,  253, 4575,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [4407, 3861, 3086, 2652,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [2146, 4416, 4478, 2702,  402, 1078,   43, 4389,    2,    0,    0],\n",
      "        [4848, 1313, 4423, 2655, 1724, 4478,    2,    0,    0,    0,    0],\n",
      "        [2032,  202, 2954,    2,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [2146, 4416, 4478, 2303, 4142, 2261,    2,    0,    0,    0,    0],\n",
      "        [4988, 2998, 2931, 4214,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [4870, 4480, 1843,    2,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [2799, 1955, 4842, 2901,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [4808, 1987,   37, 2548, 4807, 4467, 1853,    2,    0,    0,    0],\n",
      "        [4478, 4772, 4905,   37,  667,    2,    0,    0,    0,    0,    0],\n",
      "        [2146, 1325, 4776, 4467, 3817,    2,    0,    0,    0,    0,    0],\n",
      "        [1833, 2998, 2931, 4423, 3642,    2,    0,    0,    0,    0,    0],\n",
      "        [4478, 2303, 4766, 1724, 2629, 4467, 1833, 2076,    2,    0,    0],\n",
      "        [2311, 1835, 2432, 2146, 3861, 1853,    2,    0,    0,    0,    0],\n",
      "        [2146, 2090, 4478, 3711, 2867,    2,    0,    0,    0,    0,    0],\n",
      "        [4478, 2303, 3087,   37, 1667,    2,    0,    0,    0,    0,    0],\n",
      "        [1325, 4941,   43, 4392, 3077,    2,    0,    0,    0,    0,    0],\n",
      "        [2311, 2799,  643, 4478,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [4480, 1575,  253, 3485,  188, 1991, 2554, 4715, 4463,    2,    0],\n",
      "        [4478, 2303, 4715, 4186,    2,    0,    0,    0,    0,    0,    0],\n",
      "        [2485, 1853, 4467, 4392, 2768,    2,    0,    0,    0,    0,    0],\n",
      "        [2146, 4416, 4389, 4478, 4917,  402, 4250,    2,    0,    0,    0]])\n",
      "Italian batch: tensor([[12656,  4425,  2386, 10811,     2,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7217,  4615,  8539,  2331,    40, 12656, 13676,  8559,  7031,     2,\n",
      "             0],\n",
      "        [12051,  8366, 13099,  9441, 11974,  5640, 12422,     2,     0,     0,\n",
      "             0],\n",
      "        [ 4935,  7224,  2736,  8366,  6634,  7667,  5813,  9396,     2,     0,\n",
      "             0],\n",
      "        [ 9457,  7533, 13033, 13587,   850,   497,  5109,     2,     0,     0,\n",
      "             0],\n",
      "        [12656,  9158,  7628, 10621,  5652,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 4426, 11191,  1201,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [13131,  1642,   709,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7628,  8356,  2331, 12656, 11351, 11352, 13003,     2,     0,     0,\n",
      "             0],\n",
      "        [ 5592,  6973, 13033,  4847,  3698, 12694,     2,     0,     0,     0,\n",
      "             0],\n",
      "        [12656, 11351, 13676,  7394,  9578,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 8356,  2331, 12656,  8801, 13424,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 5640,  8890,  4425,  7991,     2,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [12656, 10621,  9466,  9132,  3698,  7031,     2,     0,     0,     0,\n",
      "             0],\n",
      "        [ 3264,  8818,  4708,    40,  9992,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7628, 12283,  2012,  2331,  4186,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [12656,  7628,  5580, 11441,  3698,  8126,     2,     0,     0,     0,\n",
      "             0],\n",
      "        [12656,  4288,  7031, 12016,  2574,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7628,  4425,  4089,  4724,     2,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [11583, 11570, 13032, 13027,  6166,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7628,    80,  1725,  3698,  1204,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7217,  8535,  5640,  1738,     2,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 3264,  1382,  3023,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [12083,  8121, 12890,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7628,  5133, 12656,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 5640, 13475,  5580,  4755, 13033,  4158,   497,  2534,     2,     0,\n",
      "             0],\n",
      "        [ 7628, 11583,  5640,  2103,  3588,  7701, 11969,     2,     0,     0,\n",
      "             0],\n",
      "        [12656,  7628, 13676, 13032,  1782,   521,     2,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7591,  3698,  7612,  4425, 11487,  3472, 11423,     2,     0,     0,\n",
      "             0],\n",
      "        [ 8356,  2331, 12656, 11352,  5017,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 8338,  3698,  1363, 13494,  9431,  2331,  2968,     2,     0,     0,\n",
      "             0],\n",
      "        [ 9465,  7217,  4615,  5924,     2,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [12656,  1393,  4245,  3494,    40,  7031, 13032,  9661,  3698,  2739,\n",
      "             2],\n",
      "        [13676,  5310,     2,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [13541,  2331, 12935, 12561,  4086,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 5640,  6713, 13676, 12890,  3293,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [12656, 13676,  4793,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [13634, 12990,     2,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7628,  8356,  2331, 12656, 11352, 10841,     2,     0,     0,     0,\n",
      "             0],\n",
      "        [11991,  9613,  5813,  6984,  4297,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  490, 13064,  1124, 11351, 12926,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 4400,  6634, 12090, 11583, 13312,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 4233,  8023,     2,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 8356,  2331, 12656,  8859,  4550,  3457,    40,  9992,     2,     0,\n",
      "             0],\n",
      "        [ 9465,  3264, 11374,  8366, 12656,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 4311, 13032,   566,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 8356,  2331, 12656, 11352,   700,  6259,     2,     0,     0,     0,\n",
      "             0],\n",
      "        [ 5581,  4948,  6768, 13674,     2,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 2338, 13676,  6453,  4858,  3698, 12656,     2,     0,     0,     0,\n",
      "             0],\n",
      "        [ 6634,  7223,  6981,  4426,  6310,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [   80,  7334, 12092,  3466,  4708,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [12656,  1985,  2828, 13032,  1596,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7628, 13541,  2865,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 4472,  3466,  9460, 12018,     2,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [12656, 11975,  1130,  2331,  7031,  1063,    40,  2172,     2,     0,\n",
      "             0],\n",
      "        [11351, 11975,  4632, 12371,  4234,   709,     2,     0,     0,     0,\n",
      "             0],\n",
      "        [11808,  2331, 12656,  3711,  3698,  7606,     2,     0,     0,     0,\n",
      "             0],\n",
      "        [12656, 11975,  8017, 13033,  7443,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 7628,  9007,  3575,  8221,     2,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [13676,  6453,  7218,  2363, 12656,     2,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [12656,  5580,  5405,  7747, 10418,  4288, 11165,  7340, 12011,     2,\n",
      "             0],\n",
      "        [12656, 13676,  7340,  7971,     2,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [  729,  5813,  7352,     2,     0,     0,     0,     0,     0,     0,\n",
      "             0],\n",
      "        [ 8356,  2331, 12656,  7628, 10621, 11630,     2,     0,     0,     0,\n",
      "             0]])\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:48:57.392934Z",
     "start_time": "2025-03-31T21:48:57.388021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size * 2, bias=False)\n",
    "        self.v = nn.Linear(hidden_size * 2, 1, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # hidden: [layer*D num, batch size, hidden size]\n",
    "        # encoder_outputs: [batch size, sequence length, hidden size]\n",
    "\n",
    "        # we only have 1 layer and 1 direction in the decoder RNN, drop this dimension\n",
    "        hidden = hidden.squeeze(0)  # [batch size, hidden size]\n",
    "\n",
    "        # Repeat decoder hidden state across the sequence length\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, encoder_outputs.size(1), 1)\n",
    "\n",
    "        # Concatenate the hidden state with encoder outputs\n",
    "        combined = torch.cat((hidden, encoder_outputs), dim=2)\n",
    "\n",
    "        # Compute the attention scores\n",
    "        x = torch.tanh(self.attn(combined))\n",
    "        attention = self.v(x).squeeze(2)\n",
    "        attention_weights = F.softmax(attention, dim=1)\n",
    "\n",
    "        # Compute the context as weighted sum of encoder outputs\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ],
   "id": "d6d30f8f52da1821",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:49:29.471562Z",
     "start_time": "2025-03-31T21:49:29.463544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=num_layers,\n",
    "                            batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "\n",
    "        # concatenate hidden states of the bi-directional RNN layer\n",
    "        hidden = torch.cat((hidden[0,:,:], hidden[1,:,:]), dim=1).unsqueeze(0)\n",
    "        cell = torch.cat((cell[0,:,:], cell[1,:,:]), dim=1).unsqueeze(0)\n",
    "\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention = SimpleAttention(hidden_size)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(hidden_size + embed_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "        self.attention_matrix = []\n",
    "\n",
    "    def forward(self, x, hidden, cell, encoder_outputs, store_attention=False):\n",
    "        x = self.embedding(x)\n",
    "        context_vector, attention_weights = self.attention(hidden, encoder_outputs)\n",
    "\n",
    "        if store_attention:\n",
    "          # Store attention weights for visualization\n",
    "          self.attention_matrix.append(attention_weights.detach().cpu().numpy())\n",
    "\n",
    "        lstm_input = torch.cat((x, context_vector.unsqueeze(1)), dim=2)\n",
    "\n",
    "        out, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "\n",
    "    def reset_attention_matrix(self):\n",
    "        self.attention_matrix = []"
   ],
   "id": "3661b82775d7caf2",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:50:07.117915Z",
     "start_time": "2025-03-31T21:50:06.966312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "eng_vocab_size = len(eng_word2int)\n",
    "ita_vocab_size = len(ita_word2int)\n",
    "embed_size = 256\n",
    "hidden_size = 512\n",
    "num_layers = 1\n",
    "\n",
    "# Initialize the models\n",
    "encoder = Encoder(eng_vocab_size, embed_size, hidden_size, num_layers).to(DEVICE)\n",
    "decoder = Decoder(ita_vocab_size, embed_size, hidden_size*2, num_layers).to(DEVICE)"
   ],
   "id": "9af3c4bcd9526abd",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:50:43.664922Z",
     "start_time": "2025-03-31T21:50:43.658843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def translate(encoder, decoder, sentence, eng_word2int, ita_int2word, max_length=15):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Tokenize and encode the sentence\n",
    "        input_tensor = torch.tensor([eng_word2int[word] for word in tokenize(sentence)]\n",
    "                                    + [eng_word2int[EOS_TOKEN]], dtype=torch.long)\n",
    "        input_tensor = input_tensor.view(1, -1).to(DEVICE)  # batch_first=True\n",
    "\n",
    "        # Pass the input through the encoder\n",
    "        encoder_outputs, encoder_hidden, encoder_cell = encoder(input_tensor)\n",
    "        # Initialize the decoder input with the SOS token\n",
    "        decoder_input = torch.tensor([[eng_word2int[SOS_TOKEN]]], dtype=torch.long)  # SOS\n",
    "        # Initialize the hidden state of the decoder with the encoder's hidden state\n",
    "        decoder_hidden, decoder_cell = encoder_hidden, encoder_cell\n",
    "\n",
    "        decoder.reset_attention_matrix()\n",
    "        # Decoding the sentence\n",
    "        decoded_words = []\n",
    "        last_word = torch.tensor([[eng_word2int[SOS_TOKEN]]]).to(DEVICE)\n",
    "        for di in range(max_length):\n",
    "            logits, decoder_hidden, decoder_cell = decoder(last_word, decoder_hidden,\n",
    "                                  decoder_cell, encoder_outputs, store_attention=True)\n",
    "            next_token = logits.argmax(dim=1) # greedy\n",
    "            last_word = torch.tensor([[next_token]]).to(DEVICE)\n",
    "            if next_token.item() == ita_word2int[EOS_TOKEN]:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(ita_int2word.get(next_token.item()))\n",
    "\n",
    "        return ' '.join(decoded_words)"
   ],
   "id": "9ca1fe1a033bbfd",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:50:54.748663Z",
     "start_time": "2025-03-31T21:50:54.625612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "# s/he likes music, listening to music,\n",
    "# tom likes hot chocolate\n",
    "# i want to go home now\n",
    "# tom likes chocolate\n",
    "# tom was right about that\n",
    "# tom said he would not come\n",
    "# this is a fun game\n",
    "\n",
    "sentence = \"tom likes hot chocolate\"\n",
    "translated_sentence = translate(encoder, decoder, sentence, eng_word2int, ita_int2word)\n",
    "print(\"Translated:\", translated_sentence)"
   ],
   "id": "301e2a8d068a0cab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated: sconfitto proteggere sbarazzartene considererà usciti ottuso flessibile annegarono autorità clicca siediti qualosa andarmene insufficiente rendo\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T21:53:24.170703Z",
     "start_time": "2025-03-31T21:51:16.190707Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "# Loss Function (exclude padding)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=eng_word2int[PAD_TOKEN])\n",
    "\n",
    "# Optimizers\n",
    "encoder_optimizer = torch.optim.AdamW(encoder.parameters())\n",
    "decoder_optimizer = torch.optim.AdamW(decoder.parameters())\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Training Loop\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (input_tensor, target_tensor) in enumerate(translation_dataloader):\n",
    "        input_tensor, target_tensor = input_tensor.to(DEVICE), target_tensor.to(DEVICE)\n",
    "\n",
    "        # Zero gradients of both optimizers\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        target_length = target_tensor.size(1)\n",
    "\n",
    "        # Encoder\n",
    "        encoder_output, encoder_hidden, encoder_cell = encoder(input_tensor)\n",
    "\n",
    "        # Decoder\n",
    "        decoder_input = torch.full((batch_size, 1), eng_word2int[SOS_TOKEN], dtype=torch.long).to(DEVICE)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_cell = encoder_cell\n",
    "\n",
    "        # Randomly select a word index from the target sequence\n",
    "        random_word_index = random.randint(0, target_length - 1)\n",
    "\n",
    "        loss = 0\n",
    "\n",
    "        for di in range(target_length):\n",
    "            logits, decoder_hidden, decoder_cell  = decoder(decoder_input, decoder_hidden, decoder_cell, encoder_output)\n",
    "            #if di == random_word_index:\n",
    "            #    loss = loss_fn(logits, target_tensor[:, di])\n",
    "            #    break  # Only compute loss for the randomly selected word\n",
    "            loss += loss_fn(logits, target_tensor[:,di])\n",
    "            decoder_input = target_tensor[:, di].reshape(batch_size, 1)  # Teacher forcing\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(encoder.parameters(), 2)\n",
    "        #torch.nn.utils.clip_grad_norm_(decoder.parameters(), 2)\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:  # Print loss every 10 batches\n",
    "            print(f'Epoch {epoch}, Batch {i}, Loss: {loss.item() / target_length:.4f}')\n"
   ],
   "id": "35410a339ea4d3b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 9.5263\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 43\u001B[39m\n\u001B[32m     40\u001B[39m loss = \u001B[32m0\u001B[39m\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m di \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(target_length):\n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m     logits, decoder_hidden, decoder_cell  = \u001B[43mdecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdecoder_input\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_hidden\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_cell\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoder_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     44\u001B[39m     \u001B[38;5;66;03m#if di == random_word_index:\u001B[39;00m\n\u001B[32m     45\u001B[39m     \u001B[38;5;66;03m#    loss = loss_fn(logits, target_tensor[:, di])\u001B[39;00m\n\u001B[32m     46\u001B[39m     \u001B[38;5;66;03m#    break  # Only compute loss for the randomly selected word\u001B[39;00m\n\u001B[32m     47\u001B[39m     loss += loss_fn(logits, target_tensor[:,di])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\sign_transformer\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\sign_transformer\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 45\u001B[39m, in \u001B[36mDecoder.forward\u001B[39m\u001B[34m(self, x, hidden, cell, encoder_outputs, store_attention)\u001B[39m\n\u001B[32m     42\u001B[39m lstm_input = torch.cat((x, context_vector.unsqueeze(\u001B[32m1\u001B[39m)), dim=\u001B[32m2\u001B[39m)\n\u001B[32m     44\u001B[39m out, (hidden, cell) = \u001B[38;5;28mself\u001B[39m.lstm(lstm_input, (hidden, cell))\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m out = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m.reshape(out.size(\u001B[32m0\u001B[39m), -\u001B[32m1\u001B[39m)\n\u001B[32m     46\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m out, hidden, cell\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\sign_transformer\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\sign_transformer\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\sign_transformer\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_attention(attention_matrix, input_sentence, output_sentence):\n",
    "    attention_matrix = attention_matrix.squeeze(1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    attention_heatmap = sns.heatmap(attention_matrix, annot=True, ax=ax, cmap=\"viridis\", fmt=\".2f\",\n",
    "                                    xticklabels=input_sentence, yticklabels=output_sentence)\n",
    "    plt.xlabel('Input Sequence')\n",
    "    plt.ylabel('Output Sequence')\n",
    "    plt.title('Attention Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "attention_matrix = np.array(decoder.attention_matrix)\n",
    "plot_attention(attention_matrix, tokenize(sentence), tokenize(translated_sentence))"
   ],
   "id": "a4d8a1ad341bf5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
